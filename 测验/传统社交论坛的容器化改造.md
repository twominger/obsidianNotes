![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250324205910296.png)
# 项目描述

Y公司原有一套放在公有云上基于Discuz的活动交流社区，现应公司数据安全要求和业务弹性伸缩需求进行容器化项目改造；需要将其运行在企业内部的数据中心，使用openstack私有云底座，将业务运行在K8s的容器平台中，实现业务的快速发放和应对业务在高峰时的自扩容访问，并使用MGR对数据库进行高可靠配置，同时采用ceph进行数据持久化，并通过灾备站点对生产数据进行容灾

# 实施需求：

## 1.OpenStack实施需求:

1.1运维实施团队向公司资源池申请创建一个名为EXAM_project的项目，用来进行前期业务测试，该项目可以创建10个云服务器，3个安全组、10个浮动IP、10个云硬盘
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250327225536945.png)

1.2该项目包含一个你姓名全拼的用户，该用户的密码为yutianedu@123，邮箱为你姓名的全拼@example.com，该用户为EXAM_project的普通用户
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250327225814265.png)

1.3云平台拥有一个datacenter01的主机集合，该集合包含名为osp.lab0.cn的主机
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250327225959135.png)

1.4云平台有一个可供全平台使用的centos8_4镜像，该镜像是一个qcow2的模板，使用该模板能够部署出 1核CPU 2G内存10G硬盘规格的云服务器，该镜像应该搭配mysql_flavor云主机规格来进行使用
- 创建规格（实例类型）
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250327230407627.png)
- 上传镜像
从 [CentOS Cloud Images](https://cloud.centos.org/centos/8/x86_64/images/) 下载的 qcow2 镜像（从这里下载的镜像只能使用密钥认证，见  [centos cloud 默认密码_CentOS - 酷盾](https://www.kdun.com/ask/740569.html)）
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328001502645.png)

![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328001132989.png)
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328001846014.png)

1.5 云平台有一个名为public的外部网络，在该网络中有subnet0这个子网，该子网的地址为172.17.0.0/24，网关为172.17.0.254，激活DHCP，地址池设置172.17.0.1-172.17.0.199，DNS设置223.5.5.5，8.8.8.8
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328003556931.png)
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328003617348.png)
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328003636254.png)

1.6 在云平台配置一个名为private的项目网络，在该网络中有一个名为subnet1的子网地址为172.17.10.0/24，网关为172.17.10.254，激活DHCP，地址池设置172.17.10.1-172.17.10.254，DNS设置223.5.5.5，8.8.8.8通过route0的路由器与public网络连通
- 创建私网
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328013116306.png)
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328013155812.png)
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328013504104.png)
dhcp 地址池不包含 254，与网关冲突
- 创建路由
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328013639067.png)
点击新创建的路由名称进入，添加接口
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328013813940.png)
创建完成后网络拓扑如下：
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250328013855232.png)

1.7 为云平台构建一个仅为EXAM_project可以使用的镜像，该镜像应该包含kubernetes1.31版本所需的kubeadm、kubectl以及kubelet等必备组件，并将镜像命名为k8s-image,可提供给container_flavor01和02的实例规格进行使用；container_flavor01可以创建2C2G，系统盘为20G的云服务器、container_flavor02可以创建4C4G，系统盘为20G的云服务器
- 安装 docker
[docker-ce镜像_docker-ce下载地址_docker-ce安装教程-阿里巴巴开源镜像站](https://developer.aliyun.com/mirror/docker-ce?spm=a2c6h.13651102.0.0.57e31b11JxkrEl)



1.8 为OpenStack配置高性能云存储，为了提高数据的存储效率，同时对数据进行冗余，公司决定为OpenStack对接后端分布式存储CEPH，并使用CEPH多站点进行容灾备份；通过为主站点配置cinder_pool的存储来为OpenStack的cinder提供云存储池，请为cinder组件配置该存储类型

1.9 为容器镜像仓库准备存储资源，在云平台创建一个类型为ceph名称为harbor-disk的云硬盘，大小为10G

1.10 为云服务器配置安全组和登录秘钥对；该EXAM_project拥有一个名为security01的安全组，该安全组放行3306端口；另一个名为security02的安全组放行80端口并允许icmp协议

[Openstack使用官方ubuntu和Centos镜像_openstack 锁定实例-CSDN博客](https://blog.csdn.net/zhaihaifei/article/details/78652780)
```shell
#!/bin/sh    
sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/g' /etc/ssh/sshd_config    
sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/g' /etc/ssh/sshd_config    
cp -f /home/centos/.ssh/authorized_keys /root/.ssh/    
service sshd restart    
passwd centos<<EOF    
123456  
123456  
EOF   
```

1.11为云平台创建一个名为harbor的云服务器，该云服务器使用container_flavor01规格、CentOS8_4镜像、private的网络和security02的安全组；并通过规划的业务网络IP对外使用hub.lab0.cn提供 容器镜像仓库服务，容器镜像需要使用harbor-disk提供的云硬盘进行存储，在系统的/data目录下可以找到harbor的容器数据；

1.12 使用云平台构建MySql的MGR集群实例，创建三台云服务器，主机名分别为sql01和sql02以及sql03云服务器使用mysql_flavor规格、CentOS8_4镜像、private的网络和security01的安全组，可以使用资产清单中的业务网络对外提供服务；云服务器的系统盘应使用cinder提供的ceph类型的云硬盘

1.13使用云平台构建Kubernetes的高可用集群实例，创建五台云服务器，其中四台为M01、M02、M03、N01使用container_flavor01规格;另外一台为N02使用container_flavor02规格使用；所有五台云服务器都使用k8s-img镜像、private的网络和security03的安全组，可以使用资产清单中的业务网络对外提供服务；云服务器的系统盘应使用cinder提供的ceph类型的云硬盘

## 2. CEPH实施需求：

2.1在osp的物理机上为cs01和cs02两台机器配置两套P版16.2.11的单节点ceph集群，每套集群可以使用9个OSD，无需部署dashboard和监控相关组件，仅部署mon和mgr以及OSD和相关必要组件，通过172.17.0.1的mon可以访问并使用cs01的集群，通过172.17.0.2的mon可以访问到第二套集群，其中cs01的集群为生产集群，cs02为灾备集群

2.2在cs01为osp和Mysql分别配置名为cinder-pool和mysql-pool的存储池，存储池使用RBD类型的存储，使用3副本保障数据的安全性，并创建用于对接ceph存储中RBD连接的普通用户，用户名设置为你姓名全拼的用户（例如：姓名张三，账号设置：zhangsan）对cinder-pool和 mysql-pool 存储池具有完整权限，在mysql-pool的存储池中，有一个名为mysql-data的镜像，该镜像大小为10G。

2.3在cs01为Kubernetes配置一个名为kubernetes-data的数据池和名为kubernetes-metadata元数据池，该存储池使用CephFS类型的存储配置一个k8s_fs的文件系统存储，使用3副本保障数据的安全性，并创建用于对接ceph存储中CephFS连接的普通用户，用户名设置为你姓名全拼的用户（例如：姓名张三，账号设置：zhangsan）对kubernetes-pool存储池的具有完整权限。

2.4 为OpenStack配置云硬盘多站点容灾，将CS01生产站点中的cinder_pool存储池中的RBD通过RBD镜像Mirror的方式同步到远程灾备站点CS02，同步的模式为单向模式，镜像复制方式为池模式

2.5 随着业务的使用量增加，mysql所使用的rbd镜像需要进行扩容到20G大小

2.6 运维工程师为了调整云硬盘中操作系统的数据，决定对cinder中的k8s-image镜像进行改造，使用rbd克隆技术得到克隆卷k8s-clone并将克隆的镜像挂载起来,克隆基于k8s-image的snap01快照,并且可以独立于源卷，删除镜像中k8s的配置文件，然后将其导出到，灾备站点的backup-pool的存储池中，命名为k8s-image-backup

## 3.Kubernetes实施需求：

3.1使用kubeadm部署1.31版本、根据实际生产环境需在M01-03作为集群的master节点，每个节点为资源为1C2G10Gb，N01-02作为work业务节点，01节点资源为1C2G10Gb，02节点资源为2C4G10Gb。

3.2集群内部cni网络接口采用calico-ipip模式，经过ip隧道封装通信。

3.3为防止业务pod过多、pod调用链路速度过慢、kubeproxy采用ipvs模式。

3.4通过ceph csi插件将ceph kubernetes-pool存储池作为K8s的数据存储池挂载至每个节点。

3.5 Discuz论坛网站采用dockerfile的方式封装镜像、镜像名称Discuz-nginx将镜像上传至远程harbor仓库hub.lab0.cn镜像仓库

3.6 编写discuz.yaml文件部署Discuz社区

3.7创建一个名为discuz的namespace、discuz业务所有的pod运行在该命名空间

3.8使用deplayment进行多副本部署要求3副本

3.9定义拉取镜像地址配置为内部镜像仓库[hub.lab0.cn](https://hub.lab0.cn/)

3.10在N02节点打上Discuz-node标签，根据标签选择器将所有pod调度到N02节点

3.11 Service对外访问方式使用Nodeport模式、自定义端口号使用8888

3.12限制Discuz业务pod最高使用1Gb内存、60%的CPU份额、当资源使用超过限制自动扩容副本数量、副本数量最大限制设置为5副本、最小为3副本。

## 4.Mysql数据库集群实施需求：

4.1 在sql01-03节点部署、每个节点资源1C2G10Gb，采用MGR单主模式架构部署，数据目录要求使用ceph mysql-pool存储池进行挂载。数据直接存储到ceph中。

防止MySQL数据库宕机主节点ip更换、使用keepalived配置vip使当主节点数据库宕机、不影响数据库的使用。

4.2 所有节点开启二进制日志、使用mysqldump+二进制日志实现数据备份、创建/sql_backup目录、在/sql_backup目录下在创建一个all目录一个add目录、all目录用于存储全备数据、add目录用于存储增量备份数据、备份周期为每天凌晨2点钟进行增备、每周1凌晨1点钟执行全备。每周为一个周期，在下周开始时将所有的备份数据压缩打包至/sqlzip目录。

4.3 工程师张三在操作时丢失了Discuz平台的管理员用户admin的密码，需要将其重置为yutian@123。（Discuz用户存储在pre_ucenter_members表中）

## 5. Prometheus实施需求：

5.1使用Helm包管理器安装并部署Prometheus Operator 和granfana，并设置Service对外访问方式使用Nodeport模式，Prometheus使用39090对外提供访问，grafana使用39000对外提供访问。

5.2为了确保业务Pod与监控Pod不在同一个节点上进行，避免监控数据混淆，提高监控的精确度和清晰度,要求使用affinity、taints/tolerations机制，将监控Pod调度到N01进行Pod的节点分隔。

5.3在OpenStack节点上部署OpenStack Exporters，确保Prometheus能够稳定运行并收集OpenStack各个组件的监控数据，如存储、网络、实例等集群资源，并将这些监控数据通过grafana进行可视化展示，并在Prometheus 中配置 Alertmanager，相关监控指标超80%告警，通过邮箱发送警报通知。

5.4 Prometheus对接Kubernetes 集群中配置 Prometheus CRD，用于监控集群节点、Pod 和应用服务。配置ServiceMonitor 和 PodMonitor 来监控 Kubernetes 中的服务和 Pod，并将这些监控数据通过grafana进行可视化展示，并在Prometheus 中配置 Alertmanager，相关监控指标超80%告警，通过邮件渠道发送警报通知。

5.5安装并配置Ceph Exporter，将Ceph 集群的监控指标暴露给 Prometheus在 Prometheus 中配置抓取ceph集群健康状态、osd使用率、存储池使用率等指标，并将这些监控数据通过grafana进行可视化展示，并在Prometheus 中配置 Alertmanager，相关监控指标超80%告警，通过邮件渠道发送警报通知。

5.6 安装并配置Mysql Exporter，将Mysql集群的监控指标暴露给Prometheus在 Prometheus 中配置抓取Mysql集群MySQL 执行的查询总数、当前连接到 MySQL 的客户端线程数量、当前正在执行查询的线程数量，MySQL 数据库的总连接数、慢查询的数量等指标，并将这些监控数据通过grafana进行可视化展示，并在Prometheus 中配置 Alertmanager，相关监控指标超80%告警，通过邮件渠道发送警报通知。

5.7 在 Grafana 中为 Prometheus 收集的监控数据创建易于理解和分析的图表与仪表板。创建和配置适当的 Grafana 仪表板，以展示 OpenStack、Kubernetes、Ceph、MySQL 等监控数据。使用标准模板配置仪表板和图表，确保可以实时查看各项指标，如 CPU 使用率、内存使用率、存储使用率等。