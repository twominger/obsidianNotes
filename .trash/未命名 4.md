# 戚佳 , 袁薛凯. 生成式人工智能工具使用对高校学生批判性思维与自主学习能力的影响[J]. e-Education Research, 2024, 45(12).
生成式人工智能工具为教育数字化转型带来新动力，助力人才培养。
本研究对1781名大学生进行问卷调查，探讨使用生成式人工智能工具对其批判性思维和自主学习能力的影响。
研究发现，使用生成式人工智能工具的学生的批判性思维和自主学习能力明显高于不使用此类工具的学生。
经常使用生成式人工智能工具的学生在这两个方面都比不经常使用的学生表现得更好。
与普通高校的本科生和学生相比，双一流高校的毕业生和学生通过使用生成式人工智能工具，在批判性思维和自主学习能力方面表现出更明显的提高。
学生大多使用生成式人工智能工具来提出封闭式问题，需要进一步分析以确定此类工具可以为学生提供的个性化帮助的界限。
# 孟青泉 , 贾积有. 人工智能教育研究及应用中的问题剖析与发展建议[J]. 人工智能, 2019, 3: 110-118.
多元思维路径提示，增强创新思维能力 
目前，人工智能教育系统主要以知识学习为核心，提供给学生的往往是确定性、标准化、流程化的知识，而欠缺对学生创新思维方面的引导与开发。通过提供多元思维路径提示，让学生自主探索和思考得出自己的认识和理解，系统给予积极的反馈与鼓励，在潜移默化中培养创新意识和创新能力。还可以将学生的探索过程记录下来，形成创新素材库，构建创新思维训练的大数据，以便于后期的数据挖掘。
# 李艳,许洁,贾程媛,等.大学生生成式人工智能应用现状与思考——基于浙江大学的调查[J].开放教育研究,2024,30(01):89-98.DOI:10.13966/j.cnki.kfjyyj.2024.01.010.
本研究随机调查了1190位浙江大学本科生，通过描述统计、差异检验及事后多重比较等方法，分析大学生生成式人工智能的使用现状及影响因素。研究表明，约七成受访者表示熟悉生成式人工智能；三分之二的大学生使用生成式人工智能的时间在2022年12月-2023年6月间，四分之一的大学生开始使用生成式人工智能的时间是2023年7-11月；五分之一大学生表示会经常使用，七成大学生表示会偶尔使用；大学生使用最多的生成式人工智能工具是ChatGPT；使用最多的技术是文本生成技术；最常用的生成式人工智能功能包括文本生成和信息搜索；约六成大学生学过生成式人工智能的知识或技能；大学生使用生成式人工智能的四大典型场景（课程学习、科研活动、日常生活以及升学求职）中，科研活动是最常用生成式人工智能场景；性别、年级、专业大类等变量会不同程度影响大学生使用生成式人工智能；希望学校开设生成式人工智能相关课程/讲座是大学生提出最多的建议。基于调研结果，本研究从高教管理部门、公司机构、高校和教师等角度，提出未来高校使用生成式人工智能的建议，以期为生成式人工智能融入高等教育教学实践提供参考。
# 李禹洁, 何璞. 基于 TOPSIS 法对人工智能学习软件影响不同专业类别大学生学习的评价——以 2023 “电工杯” 数学建模大赛 B 题为例[J]. Statistics and Application, 2023, 12: 1648.
人工智能已经成为近年来最具影响力的方面之一，涉及金融、医疗、交通等各个领域，在教育教学方面也起着很重要的作用。本研究以2023年“电工杯”数学建模大赛B题附件问卷调查中的4606名大学生为例，筛选出能够反映人工智能学习软件对不同专业大学生学习影响的相关指数，采用TOPSIS法对人工智能学习软件对不同专业大学生学习的影响进行评价。学习相关指数从高到低依次为理工类、经管类、艺术教育类、文法类，表明人工智能学习软件主要影响理工类大学生的学习。

# 骆飞,马雨璇.人工智能生成内容对学术生态的影响与应对——基于ChatGPT的讨论与分析[J].现代教育技术,2023,33(06):15-25.
以ChatGPT为代表的人工智能生成内容（Artificial Intelligence Generated Content,AIGC）发展日益蓬勃，引起了业界与学界的广泛讨论，然而目前对于AIGC如何影响学术生态的讨论尚不系统。基于此，文章首先梳理了AIGC的源起与发展，并讨论了ChatGPT带来的新变革。然后，文章基于学术生态的基本概念构建分析框架，讨论了AIGC对学术生产、学术评价、学术传播方面的影响，并以ChatGPT为例进行了具体分析与讨论。文章认为，以ChatGPT为代表的AIGC可以在知识生产、科学评价、快速传播等方面发挥作用，但也可能造成责任分散、潜在歧视与信任危机。最后，文章讨论了如何应对AIGC带来的风险挑战，指出未来需要进一步强化责任规范、构建审查机制与推动研究透明。文章为政策制定者理解AIGC对学术生态的影响提供了一个理解视角，并对如何科学、合理地使用AIGC提出了逻辑进路，旨在为未来学术生态的良性健康发展提供参考。

# 莫祖英, 盘大清, 刘欢, 等. 信息质量视角下 AIGC 虚假信息问题及根源分析[J]. 图书情报知识, 2023, 40(4): 32-40.
**摘要：** [目的/意义] 探讨AIGC中存在的各种虚假信息类型及其特征，对理解虚假信息产生的根源、减少AIGC中虚假信息的生成具有积极作用。[研究设计/方法] 采用数据测试实验方法，立足于信息质量视角，通过采集AIGC系统一手的测试数据和收集二手的AIGC虚假信息来剖析AIGC虚假信息类型及特征；以人工智能语言模型的信息生成过程为着力点，探析AIGC中虚假信息生成的根源。[结论/发现] AIGC虚假信息主要包括事实性虚假和幻觉性虚假两种类型，事实性虚假信息主要集中在数据错误、作者作品错误、客观事实错误、编程代码错误、机器翻译错误五个方面，而幻觉性虚假信息主要集中在虚假新闻事件、虚假学术信息、虚假健康信息和偏见与歧视方面；AIGC虚假信息产生的根源与大规模语言模型、预训练数据集和人工标注三个要素有关。[创新/价值] 采用了数据测试实验方法，并辅以二手数据的收集，全面分析了各种AIGC虚假信息的类型，并根据生成机理与表现形式将其划分为事实性虚假信息和幻觉性虚假信息，为AIGC虚假信息的进一步研究提供了理论基础。
#  AMOOZADEH M, DANIELS D, NAM D, et al. Trust in Generative AI among Students: An exploratory study; proceedings of the Proceedings of the 55th ACM Technical Symposium on Computer Science Education V 1, F, 2024 [C].

4.3.1 不信任（n=38）。
大约一半的参与者表示对 GenAI 的能力或输出缺乏信任，并强调需要人工监督和批准人工智能生成的答案。
他们认识到，人工智能并非万无一失，应该受到人类的监督，以确保准确性和可靠性。
根据受访者的说法，这种缺乏信任源于人工智能算法的偏见、错误和局限性。
一位受访者解释说：“人工智能系统在编程方面有很大的潜力，因为它们可以自动执行许多重复和繁琐的任务，根据大型数据集进行预测，甚至生成代码。
然而，也有人担心人工智能系统在编程方面的潜在负面影响。
例如，如果用于训练人工智能系统的数据不能代表整个人群，则存在偏见和歧视的风险。”
大约四分之一的受访者认为 GenAI 总体上是有帮助的。
虽然没有具体说明人工智能协助的具体任务，但他们承认 GenAI 的积极影响。
有趣的是，许多发现 GenAI 有帮助的学生也表达了对人工智能的能力或产出的不信任，尤其是那些高级计算机科学课程的学生。
例如，一名学生提到，“我把人工智能作为一种补充，而不是解决方案。
我从来没有百分之百地相信它给我的代码，而且我经常不得不修改它，或者告诉人工智能它在哪里或什么地方搞砸了。”
GenAI 学习工具可以分析和处理大量的信息，使它们能够识别模式并提供相关的见解。
被试（N-14）通过提高对问题的理解或感知问题的要求来提高。
一名学生指出：“当我们的课程给我们学习新概念以及解释我给的代码时，我会使用 ChatGPT。
在这些情况下……
比起看视频，人工智能帮助我更快地学习了这些概念……
一旦我对编程有了更多的了解，我就能更好地利用它了。”
# Almassaad A, Alajlan H, Alebaikan R. Student perceptions of generative artificial intelligence: Investigating utilization, benefits, and challenges in higher education[J]. Systems, 2024, 12(10): 385.
[Student Perceptions of Generative Artificial Intelligence: Investigating Utilization, Benefits, and Challenges in Higher Education](https://www.mdpi.com/2079-8954/12/10/385)
总体而言，本研究为高等教育学生感知和利用通用工具的方式提供了有价值的见解，这可以为与这些技术在学术背景下的采用和整合相关的教育政策和实践的设计和实施提供信息。
本研究显示 78.7%的高等教育学生经常使用通用工具，这与 b[22]的研究结果一致，即 68.9%的学生熟悉 ChatGPT。
然而，21.3%的学生不使用通用工具，主要是由于缺乏知识或兴趣。
在那些使用这些工具的人当中，主要目的包括定义或澄清概念、翻译、在写作中产生想法，以及总结学术文献。
本研究以技术接受模型（TAM）和任务-技术契合理论（TTF）为基础，全面了解影响学生对人工智能技术整合看法的复杂因素。
TAM 框架表明，学生对通用工具的有用性和易用性的看法是他们是否打算采用和利用这些技术的关键决定因素。
人们对信息准确性、学习自主性、抄袭和人际互动减少的担忧，可以通过感知有用性的视角来解释。
解决这些问题对于提高学生在学术活动中接受和采用通用工具可能是至关重要的。
TTF 理论强调将通用工具的能力与学生的教育需求结合起来。
研究结果表明，学生们看到了提高理解、学习和研究过程的潜力。
然而，工具功能和需求之间的不匹配仍然值得关注。
此外，研究表明，在某些与计算相关的领域，通用应用程序可能不太流行或处于早期阶段。
通过解决人工智能工具与不同学科学生需求之间的一致性问题，大学可以释放这些技术的潜力，以改善学习和研究。
# Baek C, Tate T, Warschauer M. “ChatGPT seems too good to be true”: College students’ use and perceptions of generative AI[J]. Computers and Education: Artificial Intelligence, 2024, 7: 100294.
使用 ChatGPT 的伦理问题主要围绕抄袭和作弊。学生们担心无意的抄袭，担心依赖
ChatGPT 可能会损害他们工作的原创性，导致潜在的学术处罚（例如，“我担心这会导
致意外抄袭的增加”）。非英语母语人士认为 ChatGPT 很有用，但担心受到学校的惩罚
。一个非英语母语的人分享道：“因为我不确定学校对这个软件的立场，我不想太频繁
地使用它，因为这会给我带来麻烦。但我发现它真的很有帮助”
对无意抄袭的焦虑和对机构惩罚的恐惧，突显了传统学术价值观与 ChatGPT 等人工智能
技术的颠覆性之间的冲突。这种紧张关系反映了面对新兴技术重新定义伦理的复杂社会
斗争（Olcottetal.，2015），揭示了在生成式人工智能时代需要重新评估学术指导方针
和政策，并为机构建立更明确的人工智能政策（Chan，2023）。
ChatGPT 是在一个庞大的文本和代码数据集上训练的，这意味着它可以继承数据中存在
的偏见。这可能导致 ChatGPT 生成歧视性或冒犯性的文本。

# 宋晨, 杨湛菲, 吴振东. 大学生作业“AI 味儿”变浓，怎么管[N]. 新华每日电讯, 2025-01-14 (006).

复旦大学近期发布《复旦大学关于在本科毕业论文（设计）中使用AI工具的规定（试行）》，明确列出了禁止使用AI工具的范围，包括禁止直接使用AI工具生成本科毕业论文（设计）的正文文本、致谢或其他组成部分等，引发关注。此前，湖北大学、福州大学、天津科技大学等多所高校也......

ZOU X, SU P, LI L, et al. AI-generated content tools and students’ critical thinking: Insights from a Chinese university [J]. IFLA Journal, 2024, 50 (2): 228-41.

王语,付裕,龙江华.AIGC下协同培育大学生数字素养与批判性思维的必要性探究[J].漫科学（科学教育）,2024(6):167-169
