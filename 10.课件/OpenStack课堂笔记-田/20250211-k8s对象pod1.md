kubectl: k8s 提供，用于管理 k8s 资源，pod、deployment...
crictl: k8s 用的，用来管理维护镜像、容器
ctr: containerd 自带
nerdctl: containerd 使用，需要单独安装
docker: docker 用的

# 命令行补全
在/etc/profile 第二行添加
```shell
source <(kubectl completion bash)
```

保存退出，刷新当前环境
```shell
[root@master ~]# source /etc/profile
```
# 设置 metrics-server
```shell
[root@master ~]# kubectl top node
error: Metrics API not available
```
k8s里面如果想要通过top命令进行查询节点/容器的cpu和mem使用情况，那么依赖于一个插件。
将components.yaml文件上传到master，之后执行
```shell
[ root@master ~]# kubectl create -f components.yaml
```
![[附件/components.yaml]]
```shell
[root@master ~]# kubectl get pod -A

kube-system        metrics-server-55cd65d558-tphx7            1/1     Running   0              44s

```
这时候再使用top命令查询
```shell
[root@master ~]# kubectl top node
NAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
master   91m          4%     1192Mi          15%
node1    60m          3%     770Mi           9%
node2    48m          2%     848Mi           10%
```

# 理解 namespace 命令空间
namespace后续会简写为 ns
命名空间其实就是逻辑隔离。

```shell
[root@master ~]# kubectl config get-contexts
CURRENT   NAME                          CLUSTER      AUTHINFO           NAMESPACE
*         kubernetes-admin@kubernetes   kubernetes   kubernetes-admin
```

修改当前所在的命名空间
```shell
[root@master ~]# kubectl config set-context --current --namespace kube-system
Context "kubernetes-admin@kubernetes" modified.

[root@master ~]# kubectl config get-contexts
CURRENT   NAME                          CLUSTER      AUTHINFO           NAMESPACE
*         kubernetes-admin@kubernetes   kubernetes   kubernetes-admin   kube-system
```

为了方便后续ns操作，提供一个脚本
```shell
[root@master ~]# chmod +x kubens
[root@master ~]# mv kubens /usr/bin/
[ root@master ~]# kubens
```
[kubens](https://notes-ming.oss-cn-beijing.aliyuncs.com/files/kubens)
![[100.附件/kubens]]

# k8s架构
官方架构介绍： [Kubernetes 架构 | Kubernetes](https://kubernetes.io/zh-cn/docs/concepts/architecture/)
![image.png](https://notes-ming.oss-cn-beijing.aliyuncs.com/images/20250222001624412.png)

k8s架构分为两个平面：控制平面/数据平面
组件：
- etcd：Key-Value键值存储系统（存储数据库），存储集群所有信息（用户提交的描述信息及当前集群的状态信息）
- kube-api-server: 集群的访问入口，接收外部请求处理的，而且所有的组件都需要与它交互
- kube-scheduler: 集群调度器，通过计算将对象资源绑定给某个节点
- kube-controller-manager: 保证集群中的各种资源实际状态（status）与用户定义的期望状态（spec）一致。
[解读 kubernetes Controller Manager 工作原理 : Yingchi Blog](https://blog.yingchi.io/posts/2020/7/k8s-cm-informer.html)
它会周期性检测或观测api-server，一旦某个对象有问题，位于该节点上的kubelet就会上报信息给api-server。
这时候发现有问题，controller-manager 内部的client-go模块就会生成处理事件handle events，交给对应的controller控制器去处理，
之后，controller控制器发现少了一个容器，就会将请求再次转发给 api-server ，之后就按照整个流程再次把容器创建出来。

- kubelet： 是k8s节点上的守护进程，负责容器管理、健康检查、信息状态收集上报。
- kube-proxy: 负载均衡和网络代理的组件，管理者服务和容器之间的流量转发。两种转发模式：iptables/ipvs

创建一个pod流程：
1.kubectl run .... 客户端下达任务，任务请求首先到达 api-server，api-server写入etcd；
2.kube-scheduler 周期性向 api-server 进行询问，是否存在要调度的资源；
3.api-server 查询etcd，将信息取出（创建一个什么样的资源对象），将集群信息和需要调度的信息给到 kube-scheduler；
4.scheduler检索所有的节点状态，通过调度策略选取最佳节点，将对象和节点进行绑定，之后将信息返回给 api-server，最终保存到etcd；
5.位于数据平面的 kubelet 会将自己注册到api-server上，将当前节点的os版本、cpu、内存等信息报告给 api-server，同时会询问api-server是否有调度的资源对象需要处理；
6.api-server就会告知对应的kubelet，有对象需要创建，api-server返回对象的描述信息返回给 kubelet；
7.最终kubelet将容器创建出来 kubelet-->CRI-->containerd-->container-shim-->runc-->namespace/cgroup 容器创建出来。

# k8s资源对象pod
## 到底如何理解pod
pod就相当于给容器穿上一件外衣，让容器具备了超能力。单独的容器一旦出现问题，它自己是无法自愈的。
pod是k8s管理调度的最小单位/单元。

默认情况下，一个pod中，最少有2个容器，一个是pause公共容器，一个是业务容器。
假如先排除这个pause容器，默认这个容器用户在pod中是看不到的。一个pod中可以有一个业务容器或多个业务容器。

pause容器是干什么的？
（pause）用来承载Pod的网络，让一个pod中的所有的容器共用pause这一个网络协议栈。
在k8s里面创建的pod，就会为pod分配一个ip地址，这个ip地址是给pod里面的容器共同使用的。

问题：k8s为什么要搞这么麻烦？你底层不是对接了containerd吗？直接操作底层的容器就行了，干什么还要搞一个所谓的pod概念呢？
因为k8s只需通过CRI接口规定一套pod标准即可，屏蔽掉了不同容器运行时之间的差异。为了兼容不同的容器运行时。
![[附件/Kubernetes容器编排.pptx]]
## 如何创建一个pod
两种方式:
命令行/yaml文件

命令行
k8s 1.17版本之后创建pod的命令全部为 kubectl run

pod状态：
ContainerCreating 正在创建pod（拉取镜像）
ErrImagePull 拉取镜像失败
Pending 挂起状态，比如调度找不到对应的节点
Running 运行状态，正常状态
Complete 完成状态，完成单次或循环任务
CrashLoopBackOff 容器出现错误

[root@master ~]# kubectl run pod1 --image nginx
pod/pod1 created
[root@master ~]# kubectl get pod
NAME   READY   STATUS              RESTARTS   AGE
pod1   0/1     ContainerCreating   0          3s
[root@master ~]# kubectl get pod
NAME   READY   STATUS    RESTARTS   AGE
pod1   1/1     Running   0          2m40s

[root@master ~]# kubectl get pod -o wide
NAME   READY   STATUS    RESTARTS   AGE   IP               NODE    NOMINATED NODE   READINESS GATES
pod1   1/1     Running   0          3m    10.244.166.150   node1   <none>           <none>

yaml文件方式
[root@master ~]# kubectl run pod2 --image nginx --dry-run=client -o yaml > pod2.yaml
[root@master ~]# kubectl get pod
NAME   READY   STATUS    RESTARTS   AGE
pod1   1/1     Running   0          7m34s
[root@master ~]# cat pod2.yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: pod2
  name: pod2
spec:
  containers:
  - image: nginx
    name: pod2
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}

[root@master ~]# kubectl create -f pod2.yaml
pod/pod2 created
[root@master ~]# kubectl get pod
NAME   READY   STATUS    RESTARTS   AGE
pod1   1/1     Running   0          8m25s
pod2   1/1     Running   0          3s
[root@master ~]#

--dry-run的参数值？
yaml文件的格式含义?
kubectl create 和 kubectl apply 区别？
imagePullPolicy?
